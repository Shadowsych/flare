{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Abstract\n",
    "This is a convolutional neural network that measures population density from birds-eye view images. It takes-in an input image and then detects the population density into 4 outputs:\n",
    "- 0 people = Zero Density\n",
    "- 1 to 5 people = Low Density\n",
    "- 6 to 30 = Medium Density\n",
    "- 31 to infinity = High Density"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Defining Constants\n",
    "Let's define some constants to use in our neural network for later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# directory for the training and testing images\n",
    "training_dir = \"images/training\"\n",
    "testing_dir = \"images/testing\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of training and testing images\n",
    "num_training_samples = 100\n",
    "num_testing_samples = 5\n",
    "\n",
    "# number of images to process before the weights are updated\n",
    "training_batch_size = 2\n",
    "testing_batch_size = 2\n",
    "\n",
    "# image's square dimension for the neural network (width x height)\n",
    "image_size = 244\n",
    "\n",
    "# steps is the number of images per epoch\n",
    "training_steps = np.ceil(num_training_samples / training_batch_size)\n",
    "testing_steps = np.ceil(num_testing_samples / testing_batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-Processing Image Data\n",
    "Let's pre-process image data using Image Augmentation from Keras's ImageDataGenerator class.\n",
    "\n",
    "Image augmentation allows us to create many batches of the images, which create many more diverse set of the images. Some augmentations could be rotating, stretching, zooming, etc.\n",
    "\n",
    "This helps prevent overfitting because augmentation better diversifies the data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import keras\n",
    "import tensorflow.keras as keras\n",
    "\n",
    "# import the keras image data augmentor\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 100 images belonging to 4 classes.\n"
     ]
    }
   ],
   "source": [
    "# create a data generator for the training set using the built-in mobilenet functions\n",
    "training_generator = ImageDataGenerator(\n",
    "    preprocessing_function = keras.applications.mobilenet.preprocess_input\n",
    ").flow_from_directory(\n",
    "    training_dir,\n",
    "    target_size = (image_size, image_size),\n",
    "    batch_size = training_batch_size,\n",
    "    color_mode = \"grayscale\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
