{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Abstract\n",
    "This is a convolutional neural network that measures population density from birds-eye view images. It takes-in an input image and then detects the population density into 4 outputs:\n",
    "- 0 people = Zero Density\n",
    "- 1 to 5 people = Low Density\n",
    "- 6 to 30 = Medium Density\n",
    "- 31 to infinity = High Density"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Defining Constants\n",
    "Let's define some constants to use in our neural network for later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# directory for the training and testing images\n",
    "training_dir = \"images/training\"\n",
    "testing_dir = \"images/testing\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of training and testing images\n",
    "num_training_samples = 100\n",
    "num_testing_samples = 5\n",
    "\n",
    "# number of images to process before the weights are updated\n",
    "training_batch_size = 10\n",
    "testing_batch_size = 10\n",
    "\n",
    "# image's square dimension for the neural network (width x height)\n",
    "image_size = 244\n",
    "\n",
    "# steps is the number of images per epoch\n",
    "training_steps = np.ceil(num_training_samples / training_batch_size)\n",
    "testing_steps = np.ceil(num_testing_samples / testing_batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-Processing Image Data\n",
    "Let's pre-process image data using Image Augmentation from Keras's ImageDataGenerator class.\n",
    "\n",
    "Image augmentation allows us to create many batches of the images, which create many more diverse set of the images. Some augmentations could be rotating, stretching, zooming, etc.\n",
    "\n",
    "This helps prevent overfitting because augmentation better diversifies the data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import keras\n",
    "import tensorflow.keras as keras\n",
    "\n",
    "# import the keras image data augmentor\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 100 images belonging to 4 classes.\n"
     ]
    }
   ],
   "source": [
    "# create a data generator for the training set using the built-in mobilenet functions\n",
    "training_batches = ImageDataGenerator(\n",
    "    preprocessing_function = keras.applications.mobilenet.preprocess_input\n",
    ").flow_from_directory(\n",
    "    training_dir,\n",
    "    target_size = (image_size, image_size),\n",
    "    batch_size = training_batch_size,\n",
    "    color_mode = \"grayscale\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mobile Net Model\n",
    "Let's create a CNN, specifically to work with mobile phones (since we're performing demos on a mobile camera).\n",
    "\n",
    "We're going to use a pre-trained model called MobileNet, which works very well with mobile images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import models\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "# import layers from keras\n",
    "from tensorflow.keras.layers import Dense, Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W1102 14:24:47.171740 139813018994496 deprecation.py:506] From /home/pravat/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
     ]
    }
   ],
   "source": [
    "# initialize a pre-trained weights mobile net model\n",
    "mobile = keras.applications.mobilenet.MobileNet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the last 6th layer of the model\n",
    "sixth_layer = mobile.layers[-6].output\n",
    "\n",
    "# dropout layer to get 25% of the original number of neurons in the 6th layer to reduce overfitting\n",
    "dropout_sixth_layer = Dropout(0.25)(sixth_layer)\n",
    "\n",
    "# add an output layer for the 4 categorical outputs\n",
    "output_layer = Dense(units=4, activation=\"softmax\")(dropout_sixth_layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a new neural network model using the mobile net architecture\n",
    "model = Model(inputs=mobile.input, outputs=output_layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train only on the last 15 layers of mobile net to make training faster\n",
    "for layer in model.layers[:-15]:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Metrics of the Model\n",
    "Let's create metrics (such as accuracy) to judge the performance of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the Adam (Gradient Descent) optimizer\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "# import the top 2 and top 3 accuracy metrics to checkpoint the model later\n",
    "from tensorflow.keras.metrics import categorical_accuracy, top_k_categorical_accuracy\n",
    "\n",
    "# import the callbacks for the models to use to fit to the training set\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau, ModelCheckpoint\n",
    "\n",
    "# import the measurements to determine the validity of the model\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# return the top 3 accuracy of the model\n",
    "def top_3_accuracy(y_true, y_pred):\n",
    "    return top_k_categorical_accuracy(y_true, y_pred, k=3)\n",
    "\n",
    "# return the top 2 accuracy of the model\n",
    "def top_2_accuracy(y_true, y_pred):\n",
    "    return top_k_categorical_accuracy(y_true, y_pred, k=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compile the model using the accuracy measurements above\n",
    "model.compile(Adam(lr=0.01), loss='categorical_crossentropy', metrics=[categorical_accuracy, top_2_accuracy, top_3_accuracy])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Checkpoints\n",
    "Let's define checkpoints to save the neural network whenever we reached the most accurate version of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Declare a checkpoint to save the best version of the model\n",
    "filepath = \"model.h5\"\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_top_3_accuracy', verbose=1,\n",
    "                             save_best_only=True, mode='max')\n",
    "\n",
    "# Reduce the learning rate as the learning stagnates\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_top_3_accuracy', factor=0.5, patience=2,\n",
    "                              verbose=1, mode='max', min_lr=0.00001)\n",
    "\n",
    "callbacks_list = [checkpoint, reduce_lr]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fitting The Model\n",
    "Let's fit the model to the training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit_generator(training_batches,\n",
    "                              steps_per_epoch=training_steps,\n",
    "                              validation_data=training_batches,\n",
    "                              validation_steps=testing_steps,\n",
    "                              epochs=10,\n",
    "                              verbose=1,\n",
    "                              callbacks=callbacks_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
