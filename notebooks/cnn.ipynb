{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.3"},"colab":{"name":"cnn.ipynb","provenance":[],"collapsed_sections":[],"toc_visible":true},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"VjRN4FhrxL7G","colab_type":"code","outputId":"76725e8b-3859-47f1-b0de-5e6b18b35e11","executionInfo":{"status":"ok","timestamp":1572747861848,"user_tz":360,"elapsed":552,"user":{"displayName":"Pravat Bhusal","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mBV0xcMDntbddsRcz-kxhFW-NR0p5MHMbV4t9ElSw=s64","userId":"14511535967724343411"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"AUDec-Wcv6TC","colab_type":"text"},"source":["# Abstract\n","This is a convolutional neural network that measures population density from birds-eye view images. It takes-in an input image and then detects the population density into 4 outputs:\n","- 0 people = Zero Density\n","- 1 to 5 people = Low Density\n","- 6 to 30 = Medium Density\n","- 31 to infinity = High Density"]},{"cell_type":"markdown","metadata":{"id":"W5OY4koRv6TF","colab_type":"text"},"source":["# Defining Constants\n","Let's define some constants to use in our neural network for later."]},{"cell_type":"code","metadata":{"id":"WZFhf5Nvv6TH","colab_type":"code","colab":{}},"source":["# import numpy\n","import numpy as np\n","\n","# set the random number generator of numpy\n","from numpy.random import seed\n","seed(1)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Z4s14DdIv6TM","colab_type":"code","colab":{}},"source":["# how aggressive will be the data augmentation / transformation\n","transformation_ratio = .05"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"2vC_J2K6v6TP","colab_type":"code","colab":{}},"source":["# number of training and testing images\n","num_training_samples = 100\n","num_testing_samples = 60\n","\n","# number of images to process before the weights are updated: try 4, 8, 16, 32, etc. depending on the CPU/GPU memory capacity\n","training_batch_size = 16\n","testing_batch_size = 8\n","\n","# image's square dimension for the neural network (width x height)\n","image_size = 224\n","\n","# steps is the number of images per epoch\n","training_steps = np.ceil(num_training_samples / training_batch_size)\n","testing_steps = np.ceil(num_testing_samples / testing_batch_size)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"SqG-PwBdv6TS","colab_type":"text"},"source":["# Pre-Processing Image Data\n","Let's pre-process image data using Image Augmentation from Keras's ImageDataGenerator class.\n","\n","Image augmentation allows us to create many batches of the images, which create many more diverse set of the images. Some augmentations could be rotating, stretching, zooming, etc.\n","\n","This helps prevent overfitting because augmentation better diversifies the data set."]},{"cell_type":"code","metadata":{"id":"80FZvug1v6TT","colab_type":"code","outputId":"50c4a0eb-081f-410f-8cb8-8382f1046470","executionInfo":{"status":"ok","timestamp":1572747863396,"user_tz":360,"elapsed":2039,"user":{"displayName":"Pravat Bhusal","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mBV0xcMDntbddsRcz-kxhFW-NR0p5MHMbV4t9ElSw=s64","userId":"14511535967724343411"}},"colab":{"base_uri":"https://localhost:8080/","height":63}},"source":["# import keras\n","import tensorflow.keras as keras\n","\n","# seed the random number generator of tensorflow\n","from tensorflow import set_random_seed\n","set_random_seed(2)"],"execution_count":5,"outputs":[{"output_type":"display_data","data":{"text/html":["<p style=\"color: red;\">\n","The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n","We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n","or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n","<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}}]},{"cell_type":"code","metadata":{"id":"yvRk9KD8v6TW","colab_type":"code","colab":{}},"source":["# import the keras image data augmentor\n","from tensorflow.keras.preprocessing.image import ImageDataGenerator"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"MQ510TtVv6TZ","colab_type":"code","outputId":"16082cd9-6489-41c8-8f13-9cad996357cf","executionInfo":{"status":"ok","timestamp":1572747863512,"user_tz":360,"elapsed":2134,"user":{"displayName":"Pravat Bhusal","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mBV0xcMDntbddsRcz-kxhFW-NR0p5MHMbV4t9ElSw=s64","userId":"14511535967724343411"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["# create a data generator for the training set\n","training_batches = ImageDataGenerator(\n","    rescale= 1.0 / 255,\n","    rotation_range = transformation_ratio,\n","    shear_range = transformation_ratio,\n","    zoom_range = transformation_ratio,\n","    cval = transformation_ratio,\n","    horizontal_flip=True,\n","    vertical_flip=True,\n",").flow_from_directory(\n","    \"drive/My Drive/Flare/images/training\",\n","    target_size = (image_size, image_size),\n","    batch_size = training_batch_size\n",")"],"execution_count":7,"outputs":[{"output_type":"stream","text":["Found 100 images belonging to 4 classes.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"oe3qecSgv6Te","colab_type":"code","outputId":"3fe0bafe-2431-470e-aa4d-3f3f73427e9d","executionInfo":{"status":"ok","timestamp":1572747863515,"user_tz":360,"elapsed":2127,"user":{"displayName":"Pravat Bhusal","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mBV0xcMDntbddsRcz-kxhFW-NR0p5MHMbV4t9ElSw=s64","userId":"14511535967724343411"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["# create a data generator for the testing set using the built-in mobilenet functions\n","testing_batches = ImageDataGenerator(\n","    rescale = 1.0 / 255\n",").flow_from_directory(\n","    \"drive/My Drive/Flare/images/testing\",\n","    target_size = (image_size, image_size),\n","    batch_size = testing_batch_size\n",")"],"execution_count":8,"outputs":[{"output_type":"stream","text":["Found 60 images belonging to 4 classes.\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"MOYF3N3Zv6Th","colab_type":"text"},"source":["# Convolutional Neural Network\n","Let's create a convolutional neural network to classify the image based on the categories."]},{"cell_type":"code","metadata":{"id":"FXj1IU9tv6Ti","colab_type":"code","colab":{}},"source":["# import the basic model class\n","from tensorflow.keras.models import Model\n","\n","# import the xception model\n","from tensorflow.keras.applications.vgg16 import VGG16\n","\n","# import layers\n","from tensorflow.keras.layers import GlobalMaxPooling2D, Dropout, Dense"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"yC_g3x00v6Tm","colab_type":"code","outputId":"ae141882-c006-4245-d3da-41c14fe8ea6e","executionInfo":{"status":"ok","timestamp":1572747864980,"user_tz":360,"elapsed":3574,"user":{"displayName":"Pravat Bhusal","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mBV0xcMDntbddsRcz-kxhFW-NR0p5MHMbV4t9ElSw=s64","userId":"14511535967724343411"}},"colab":{"base_uri":"https://localhost:8080/","height":88}},"source":["# use the pre-tained VGG16 model\n","base_model = VGG16(input_shape = (image_size, image_size, 3), weights = \"imagenet\", include_top = False)"],"execution_count":10,"outputs":[{"output_type":"stream","text":["WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n","Instructions for updating:\n","If using Keras pass *_constraint arguments to layers.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"OW17-Ceiv6Tp","colab_type":"code","colab":{}},"source":["# add a MaxPooling layer\n","pool_layer = GlobalMaxPooling2D()(base_model.output)\n","\n","# add a Dropout layer to prevent overfitting\n","dropout_layer = Dropout(rate=0.20)(pool_layer)\n","\n","# add the output layer to the neural network\n","output_layer = Dense(units = 4, activation = \"softmax\")(dropout_layer)\n","model = Model(base_model.input, output_layer)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"mQPVxalUv6Tu","colab_type":"code","colab":{}},"source":["# do not train the layers from the base (original) Xception model\n","for layer in base_model.layers:\n","    layer.trainable = False"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"YxPAcsTvv6Tx","colab_type":"code","colab":{}},"source":["# compile the model using the nadam (stochastic Gradient Descent) optimizer\n","model.compile(\n","    optimizer=\"nadam\",\n","    loss='categorical_crossentropy',\n","    metrics=[\"accuracy\"]\n",")"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"HV4PhZ6Bv6T0","colab_type":"text"},"source":["# Callbacks\n","Let's define Callbacks to save the neural network whenever we reached the most accurate version of the model."]},{"cell_type":"code","metadata":{"id":"IBQmwJMav6T1","colab_type":"code","colab":{}},"source":["# import the callbacks for the models to use to fit to the training set\n","from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"P_r8DlyDv6T4","colab_type":"code","colab":{}},"source":["# declare a checkpoint to save the best version of the model\n","model_file = \"model.h5\"\n","checkpoint = ModelCheckpoint(model_file, monitor = \"val_acc\", save_best_only = True, mode = \"max\")\n","\n","# early stop the model as the validation accuracy stagnates\n","# early_stop = EarlyStopping(monitor = \"val_acc\", patience = 5, verbose = 0)\n","\n","# reduce the learning rate as the learning stagnates\n","# reduce_lr = ReduceLROnPlateau(monitor=\"val_acc\", factor=0.5, patience=2, mode=\"max\", min_lr=0.00001)\n","\n","callbacks_list = [checkpoint]"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"sHmORs7mv6T7","colab_type":"text"},"source":["# Fitting The Model\n","Let's fit the model to the training set."]},{"cell_type":"code","metadata":{"id":"6Vh1gm1uv6T8","colab_type":"code","outputId":"b3fcc139-3118-48c4-f039-42764f4b8578","executionInfo":{"status":"error","timestamp":1572747896446,"user_tz":360,"elapsed":34994,"user":{"displayName":"Pravat Bhusal","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mBV0xcMDntbddsRcz-kxhFW-NR0p5MHMbV4t9ElSw=s64","userId":"14511535967724343411"}},"colab":{"base_uri":"https://localhost:8080/","height":918}},"source":["classifier = model.fit_generator(\n","    training_batches,\n","    steps_per_epoch = training_steps,\n","    validation_data = testing_batches,\n","    validation_steps = testing_steps,\n","    epochs = 100,\n","    verbose = 1,\n","    callbacks = callbacks_list\n",")"],"execution_count":16,"outputs":[{"output_type":"stream","text":["Epoch 1/100\n","6/7 [========================>.....] - ETA: 0s - loss: 1.5700 - acc: 0.2500Epoch 1/100\n","8/7 [==================================] - 2s 301ms/step - loss: 1.3384 - acc: 0.3500\n","7/7 [==============================] - 9s 1s/step - loss: 1.5527 - acc: 0.2900 - val_loss: 1.3442 - val_acc: 0.3500\n","Epoch 2/100\n","6/7 [========================>.....] - ETA: 0s - loss: 1.4935 - acc: 0.3810Epoch 1/100\n","8/7 [==================================] - 2s 200ms/step - loss: 1.2391 - acc: 0.4000\n","7/7 [==============================] - 3s 391ms/step - loss: 1.4917 - acc: 0.3700 - val_loss: 1.2740 - val_acc: 0.4000\n","Epoch 3/100\n","6/7 [========================>.....] - ETA: 0s - loss: 1.2999 - acc: 0.3452Epoch 1/100\n","8/7 [==================================] - 2s 200ms/step - loss: 1.2154 - acc: 0.4667\n","7/7 [==============================] - 3s 414ms/step - loss: 1.2737 - acc: 0.3700 - val_loss: 1.2316 - val_acc: 0.4667\n","Epoch 4/100\n","6/7 [========================>.....] - ETA: 0s - loss: 1.2828 - acc: 0.4405Epoch 1/100\n","8/7 [==================================] - 2s 201ms/step - loss: 1.1836 - acc: 0.4667\n","7/7 [==============================] - 3s 399ms/step - loss: 1.2986 - acc: 0.4400 - val_loss: 1.1979 - val_acc: 0.4667\n","Epoch 5/100\n","6/7 [========================>.....] - ETA: 0s - loss: 1.2938 - acc: 0.4405Epoch 1/100\n","8/7 [==================================] - 2s 193ms/step - loss: 1.1505 - acc: 0.5000\n","7/7 [==============================] - 3s 428ms/step - loss: 1.2339 - acc: 0.4800 - val_loss: 1.1888 - val_acc: 0.5000\n","Epoch 6/100\n","6/7 [========================>.....] - ETA: 0s - loss: 1.0159 - acc: 0.5595Epoch 1/100\n","8/7 [==================================] - 2s 194ms/step - loss: 1.1225 - acc: 0.5500\n","7/7 [==============================] - 3s 421ms/step - loss: 1.0566 - acc: 0.5400 - val_loss: 1.1298 - val_acc: 0.5500\n","Epoch 7/100\n","6/7 [========================>.....] - ETA: 0s - loss: 1.0998 - acc: 0.4762Epoch 1/100\n","8/7 [==================================] - 2s 197ms/step - loss: 1.1806 - acc: 0.5833\n","7/7 [==============================] - 3s 455ms/step - loss: 1.0767 - acc: 0.5300 - val_loss: 1.1596 - val_acc: 0.5833\n","Epoch 8/100\n","6/7 [========================>.....] - ETA: 0s - loss: 0.9921 - acc: 0.6190Epoch 1/100\n","8/7 [==================================] - 2s 199ms/step - loss: 1.1222 - acc: 0.5833\n","7/7 [==============================] - 3s 412ms/step - loss: 0.9934 - acc: 0.6200 - val_loss: 1.1020 - val_acc: 0.5833\n","Epoch 9/100\n"],"name":"stdout"},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-16-f4577abf207c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mverbose\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0mcallbacks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcallbacks_list\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m )\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   1294\u001b[0m         \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1295\u001b[0m         \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1296\u001b[0;31m         steps_name='steps_per_epoch')\n\u001b[0m\u001b[1;32m   1297\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1298\u001b[0m   def evaluate_generator(self,\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training_generator.py\u001b[0m in \u001b[0;36mmodel_iteration\u001b[0;34m(model, data, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch, mode, batch_size, steps_name, **kwargs)\u001b[0m\n\u001b[1;32m    263\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    264\u001b[0m       \u001b[0mis_deferred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_compiled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 265\u001b[0;31m       \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mbatch_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    266\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    267\u001b[0m         \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight, reset_metrics)\u001b[0m\n\u001b[1;32m   1015\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_update_sample_weight_modes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample_weights\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1016\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1017\u001b[0;31m       \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1018\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1019\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mreset_metrics\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   3474\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3475\u001b[0m     fetched = self._callable_fn(*array_vals,\n\u001b[0;32m-> 3476\u001b[0;31m                                 run_metadata=self.run_metadata)\n\u001b[0m\u001b[1;32m   3477\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_fetch_callbacks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3478\u001b[0m     output_structure = nest.pack_sequence_as(\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1470\u001b[0m         ret = tf_session.TF_SessionRunCallable(self._session._session,\n\u001b[1;32m   1471\u001b[0m                                                \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1472\u001b[0;31m                                                run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1473\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1474\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"code","metadata":{"id":"nwXDF8-jv6UA","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}